## Overview

Amazon RDS for PostgreSQL supports **logical replication** by streaming **Write-Ahead Log (WAL)** changes using **logical replication slots**. This allows you to capture and stream database changes to external systems (not necessarily replicas), such as AWS DMS or custom consumers running on EC2.

Logical replication works at a **database level** and allows **table-level replication**, making it suitable for migrations, integrations, and change data capture (CDC) use cases.

---

## Memory Hook üß†

Think of **logical replication** as:

> **"PostgreSQL tells what changed in the table instead of copying the whole data."**

* Physical replication = copies blocks
* Logical replication = streams **row-level changes**

---

## Key Concepts

---

## Aurora PostgreSQL: WAL vs Redo Log (Important Clarification)

A common point of confusion is whether **Aurora PostgreSQL uses WAL or redo logs**. The correct answer is: **both exist, but at different layers**.

### Memory Hook üß†

> **PostgreSQL thinks in WAL. Aurora stores changes as redo logs.**

You interact with **WAL**. Aurora internally manages **redo logs**.

### PostgreSQL Engine Layer (What You See)

* Aurora PostgreSQL **still generates WAL records**
* WAL is used for:

  * Crash recovery logic
  * Logical replication
  * Streaming replication
  * Logical decoding (`wal2json`, `test_decoding`)
* WAL-related settings still apply:

  * `wal_level`
  * `pg_replication_slots`
  * `pg_recvlogical`

Logical replication in Aurora **reads decoded WAL**, exactly like standard PostgreSQL.

### Aurora Storage Layer (What AWS Manages)

* Aurora **does not store traditional WAL files on local disk**
* Instead, WAL records are:

  * Converted into **redo log records**
  * Sent over the network
  * Persisted across **6 copies in 3 AZs**
* Storage nodes apply redo records directly to data pages

This distributed redo log design is what makes Aurora:

* Faster at replication
* More durable
* Able to recover without replaying large WAL files

### Why Logical Replication Still Works

Logical replication happens **before** data reaches the storage layer:

* It consumes WAL from the PostgreSQL engine
* It does not depend on how Aurora stores data internally

That‚Äôs why:

### Logical replication slots work
 > **Logical replication slots work because Aurora PostgreSQL still generates WAL at the database engine level, which slots can safely track and consume.**
### AWS DMS works
 > **AWS DMS works because it reads decoded WAL changes from PostgreSQL logical replication slots, not from Aurora‚Äôs internal storage layer.**
### (For consistency, your WAL retention line)
 > **If a replication slot is created but no client reads from it, PostgreSQL keeps the WAL instead of deleting it, which can cause storage growth.**

### Summary Table

| Aspect                      | Standard PostgreSQL | Aurora PostgreSQL |
| --------------------------- | ------------------- | ----------------- |
| WAL generated by engine     | Yes                 | Yes               |
| WAL visible to users        | Yes                 | Yes               |
| WAL stored as files         | Yes                 | No                |
| Redo log in storage layer   | No                  | Yes               |
| Logical replication support | Yes                 | Yes               |

---

### Write-Ahead Log (WAL)

* WAL records every change made to the database
* Logical replication **decodes** WAL records into readable change events (INSERT, UPDATE, DELETE)

### Logical Replication Slot

* A **logical slot** tracks how much WAL has been consumed by a client
* Slots are created **per database**
* Slots **do not know who the consumer is**
* If a slot is not actively consumed, **WAL keeps accumulating**, which can **fill up storage** ‚ùó

### Logical Decoding

* Converts raw WAL into structured change data
* Uses output plugins to format the changes

Supported plugins in RDS PostgreSQL:

* `test_decoding` (simple, human-readable)
* `wal2json` (JSON output, commonly used for CDC tools)

---

## Common Logical Replication Clients

* **AWS Database Migration Service (DMS)**
* Custom consumers using:

  * `pg_recvlogical`
  * Custom applications on EC2

‚ö†Ô∏è The target **does not need to be a replica database**.

---

## Enabling Logical Replication on RDS PostgreSQL

### Required Roles

The user must have:

* `rds_superuser` ‚Üí to enable logical replication
* `rds_replication` ‚Üí to manage replication slots and stream data

---

### Required Parameter Changes

Set the following parameters:

* `rds.logical_replication = 1` (static)
* `wal_level = logical`
* `max_wal_senders`
* `max_replication_slots`
* `max_connections`

‚ö†Ô∏è These settings **increase WAL generation**. Enable them **only when needed**.

üîÅ **DB reboot required** for `rds.logical_replication` to take effect.

---

## Working with Logical Replication Slots

### Create a Logical Slot

```sql
SELECT * FROM pg_create_logical_replication_slot('test_slot', 'test_decoding');
```

### List Existing Slots

```sql
SELECT * FROM pg_replication_slots;
```

### Drop a Logical Slot

```sql
SELECT pg_drop_replication_slot('test_slot');
```

‚ö†Ô∏è Always drop unused slots to avoid WAL bloat.

---

## Streaming Changes Using pg_recvlogical

`pg_recvlogical` is a PostgreSQL client tool used to consume logical replication streams.

Example:

```bash
pg_recvlogical -d postgres --slot test_slot -U postgres \
--host <instance-endpoint> \
-f - --start
```

Requirements:

* Replication connection allowed
* Proper authentication configured

---

## Replicating Table-Level Data (Logical Replication)

Logical replication allows **table-by-table replication** using **publications** and **subscriptions**.

---

## Step 1: Create Source Table

```sql
CREATE TABLE testtab (slno int PRIMARY KEY);
```

Insert data:

```sql
INSERT INTO testtab VALUES (generate_series(1,1000));
```

---

## Step 2: Create Publication (Source DB)

Create publication:

```sql
CREATE PUBLICATION testpub FOR TABLE testtab;
```

Verify publication:

```sql
SELECT * FROM pg_publication;
```

Verify tables:

```sql
SELECT * FROM pg_publication_tables;
```

### Replicate All Tables

```sql
CREATE PUBLICATION testpub FOR ALL TABLES;
```

### Add New Table to Existing Publication

```sql
ALTER PUBLICATION testpub ADD TABLE new_table;
```

---

## Step 3: Create Target Table

(Target DB must have matching schema)

```sql
CREATE TABLE testtab (slno int PRIMARY KEY);
```

Verify target is empty:

```sql
SELECT count(*) FROM testtab;
```

---

## Step 4: Create Subscription (Target DB)

```sql
CREATE SUBSCRIPTION testsub
CONNECTION 'host=<source-endpoint> port=5432 dbname=<source_db> user=<user> password=<password>'
PUBLICATION testpub;
```

Verify subscription:

```sql
SELECT oid, subname, subenabled, subslotname, subpublications FROM pg_subscription;
```

---

## Initial Data Load

* Subscription creation automatically:

  * Copies existing data
  * Starts streaming ongoing changes

Verify initial load:

```sql
SELECT count(*) FROM testtab;
```

---

## Replication Slot Verification (Source DB)

```sql
SELECT * FROM pg_replication_slots;
```

Important fields:

* `slot_type = logical`
* `active = true`
* `confirmed_flush_lsn` tracks consumer progress

---

## Testing Replication

Insert new data in source:

```sql
INSERT INTO testtab VALUES (generate_series(1001,2000));
```

Verify source:

```sql
SELECT count(*) FROM testtab;
```

Verify target:

```sql
SELECT count(*) FROM testtab;
```

‚úÖ Counts should match.

---

## Refreshing Subscription After Adding Tables

When new tables are added to a publication, you **must refresh the subscription**:

```sql
ALTER SUBSCRIPTION testsub REFRESH PUBLICATION;
```

What this does:

* Fetches new table metadata
* Starts replication for newly added tables

---

## Common Pitfalls ‚ö†Ô∏è

* Leaving logical slots unused ‚Üí **disk fills up**
* Forgetting to refresh subscription after adding tables
* Schema mismatch between source and target
* Insufficient replication slots or WAL senders

---

## FAQ

### Q1: Is logical replication the same as read replicas?

No. Logical replication works at **table/row level**, while read replicas use **physical replication**.

### Q2: Does the target have to be PostgreSQL?

No. Logical replication streams changes; the consumer can transform or load data elsewhere.

### Q3: What happens if the consumer stops reading?

WAL accumulates and can **exhaust storage**.

### Q4: Can I replicate only specific tables?

Yes, using **publications**.

### Q5: Is a reboot required?

Yes, when enabling `rds.logical_replication`.

### Q6: Which plugin should I use?

* `test_decoding` ‚Üí learning/debugging
* `wal2json` ‚Üí production CDC pipelines

---

## Quick Mental Summary üß†

**Enable ‚Üí Create Slot ‚Üí Publish Tables ‚Üí Subscribe ‚Üí Stream Changes**
